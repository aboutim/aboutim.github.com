<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用 PowerCLI 批量获取 VMX 并注册到 VC 清单中]]></title>
    <url>%2F2017%2F07%2F17%2Fpowecli-register-datastore-vmx%2F</url>
    <content type="text"><![CDATA[适合场景 存储搬迁到别的机房，VM 计划性停机，使用需要批量的把 VM 注册到新机房的计算资源池中。 适合找出没有注册到VC指定位置中的非活动 VM 思路 获取 Datastore 的信息 ，示例是获取集群内的 Datastore 1$Datastoreinfo = Get-Datastore -Nmae &apos;DatastoreName&apos; | %&#123;Get-View $_.Id&#125; 处理 Datastore 的信息 1$DsBrowser = Get-View $Datastoreinfo.browser 新建搜索对象，附加搜索条件 123$SearchSpec = New-Object VMware.Vim.HostDatastoreBrowserSearchSpec$SearchSpec.matchpattern = &quot;*.vmx&quot;$DsPath = &quot;[&quot; + $Datastoreinfo.Name + &quot;]&quot; 搜索并展现 1$SearchResult = $DsBrowser.SearchDatastoreSubFolders($DsPath, $SearchSpec) | where &#123;$_.FolderPath -notmatch &quot;.snapshot&quot;&#125; | %&#123;$.FolderPath + ($_.File | select Path).Path&#125; 最终输出的结果为 1[datastorename] VMnameFolder/VMname.vmx 注册VM 1New-VM -Name $VMname -VMFilePath $VMXpath -ResourcePool $vmhost -Location $VMFolder -RunAsync *如果 VM 名称曾经修改过，又没有做过 XvMotion (storeger vMotion) VMnameFolder以及目录下所有的VM文件，还是原来旧的 VMname 命名。 扩展 可套用 foreach 循环，对多个 Datastore 进行检索VMX文件 如果是场景1，可在 VM 是注册状态下，使用 PowerCLI 直接获取 VMX_PATH 路径以及对应的 VMname，位置信息等，导出为表，将来可使用 PowerCLI 根据表的信息进行注册。]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>PowerCLI</tag>
        <tag>VMWare运维</tag>
        <tag>VMX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算工程技术点汇总]]></title>
    <url>%2F2017%2F02%2F28%2Fcloud-tech-list%2F</url>
    <content type="text"><![CDATA[基础架构计算 X86服务器 CPU 内核 缓存 工艺 指令 功耗 GPU 显存 CUDA 功耗 Memmory 工艺 频率 时延 DISK SSD 存储颗粒 TLC、MLC、SLC、Optane 主控、预留空间、P/E 垃圾回收、损耗均衡、TRIM HDD 转速（5K、7.2K、10K、15K） 尺寸（2.5、3.5） IDE、ACHI、Nvme 接口协议 SATA、SAS、U.2、PCI-e 接口 Raid card 缓存 接口 模式（直通） 兼容性（特别是SDS） Network card intel DPDK vxlan offload 虚拟化 Hypervisor VMWare Xen KVM Hyper-V 容器 Docker CoreOS UnixLXC Unikernel 网络 VPC（虚拟私有网络） SDN（软件定义网络，控制平面与数据平台面分开） CDN（内容分发网络） NFV（网络功能虚拟化） Overlay (实现多租户网络层面隔离 VXLAN、NVGRE、STT) GRE/VPN/专线接入 公网IP动态供给 LoadBlanche（负载均衡） DNS/DHCP 基于 CLOS 组网架构 存储 网络存储 NFS v4 Ceph NAS 对象存储 AWS S3 Swift 各家公有云 块存储 FC-SAN IP-SAN DAS 集群文件系统 VMFS (VMware) GlusterFS WAFL (netapp) 软件定义存储 VMWare VSAN HUAWEI FusionStorage Veritas InfoScale Storage Ceph GlusterFS Sheepdog 存储虚拟化 EMC VPLEX IBM SVC HDS VSP 数据管理 数据压缩 重复数据删除 数据备份 同步/复制 IDC 基础设施 供电系统 UPS 双路市电 柴油发电机 冷却系统与环境控制 冷热空气流 恒定温湿度 网络概况 多线BGP网络 DDos防御分流 综合布线 机房建筑 楼宇抗震 防火灭火 安保计划与措施 授权进出 值班机制 云平台自助服务门户 身份验证 服务目录 主机 通用计算型 内存大容量型 IO 密度型 GPU 计算型 容器 物理服务器 存储 硬盘 NAS ISCSI 对象存储 网络 VPC 公网IP 私有网络 负载均衡 流量镜像 DNS、DHCP CDN 抗D 防火墙 操作系统映像 Windows Server 2008/2012/2016 Desktop Win7/8/10 Linux RedHat/Centos Ubuntu Debian SUSE SQL/NOSQL SQL Server MySQL PostgreSQL MongoDB Cassandra 缓存 Memcached Redis 大数据 Hadoop Spark HBase Storm Elasticsearch Zookeeper 拓扑图示 弹性伸缩 基于条件的触发，条件包括不限于时间、负载 适用对象包括不限于 主机、硬盘容量、网络带宽 资源编排 自助注册 权限控制 计量计费 工单系统 操作记录 监控告警 监控走势图 关键指标 CPU/MEM/DISK_SIZE/DISK_IO 备份快照 定时备份 在线快照 重定向恢复 归档 后台管理门户/BOSS 平台展板 资源管理 工单系统后台 资源配额 计量计费后台 系统映像管理 SAAS 发布 管理维护 监控告警 权限控制 安全审计 日志服务 解决方案 VPC解决方案 混合云解决方案 运维开发 流程开发 开发语言 Java Go Python Javascript PHP Ruby 意识形态名词 双模IT 私有云 混合云 行业云 政企云 金融云 公有云 成本 双路服务器比四路效能更高，性价比更优 冷数据应存放在成本低廉的存储设备 闪存的每GB成本并不比机械硬盘高多少 集中式存储是软硬件捆绑的商业产品，成本昂贵 分布式存储成熟度已经接近集中式存储，不绑定硬件 考虑2U4Node的服务器机型，节省机柜空间 只关注一次性投入成本，忽略后续投入成本是不可取的 人力也是成本，尽量依赖完善标准的自助服务满足用户大部分需求。 量大可考虑定制服务器，减少用不上的元器件不单止压缩成本也减少故障点 部分内容摘自 StuQ 的技能图谱]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维知识技能点汇总]]></title>
    <url>%2F2017%2F02%2F11%2Fops-tech-list%2F</url>
    <content type="text"><![CDATA[硬件服务器 形态 塔式 刀片 机架式 管理 带外网络管理 启动固件模式 Legacy BIOS UEFI CPU 内核 缓存 工艺 指令 功耗 GPU 显存 CUDA 功耗 Memmory 工艺 频率 时延 DISK SSD 存储颗粒 TLC、MLC、SLC、Optane 主控、预留空间、P/E 垃圾回收、损耗均衡、TRIM HDD 转速（5K、7.2K、10K、15K） 尺寸（2.5、3.5） IDE、ACHI、Nvme 接口协议 SATA、SAS、U.2、PCI-e 接口 Raid card 缓存 接口 模式（直通） 兼容性（特别是SDS） Network card intel DPDK vxlan offload 存储 存储 传统存储(共享式存储) 设备类型 控制器（机头） 磁盘柜 FC 交换机 存储网关（存储虚拟化） 存储系统 ONtap (NETAPP) EqualLogic (DELL) VNXe (EMC) VMX (EMC) DS (IBM) 形态 IP-SAN FC-SAN DAS 软件定义存储 Windows Server Storege 2012 VSAN (VMWare) InfoScale Storage (Veritas) HUAWEI FusionStorage Qingcloud Storage 对象存储 AWS S3 其它公有云厂商自研 数据保护 Raid 0/1/10/5/6 Raid2.0 (以硬盘切片后更小颗粒度作为Raid对象保护方式) Raid DP (NETAPP) 数据管理 重读数据删除 数据压缩 同步/复制 快照 磁盘扫描 加密 连接方式 IP 网络(ISCSI) FC 网络 RDMA SAS NVMeF 网络 TCP/IP协议 抓包 tcpdump 动静态路由 VPN DHCP 其它设备 堡垒机 IDS、IPS 虚拟化 虚拟化概念 半虚拟化 全虚拟化 虚拟化原理 虚拟化基础功能 CPU 内存 存储 网络 热插拔 动态迁移 快照 虚拟化管理工具 OpenStack CloudStack VMware vCenter VMware vCLOUD OpenNebula 基础服务 FTP DNS SAMBA EMAIL NTP DHCP YUM WSUS AD 平台工具 Nagios Puppet Zabbix Cacti Elasticsearch 脚本 shell Python Perl Powershell Linux 基础 基本操作命令 Linux内置编辑器 其它 安全意识 责任心 沟通方式/技巧 推进/该散 进取心/记录分享 部分内容摘自 StuQ 的技能图谱]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行批量克隆 VM 报由文件[datastore1] VM1/VM1.vmdk 引起的错误]]></title>
    <url>%2F2017%2F01%2F20%2Fmulti-clone-vm-error-case%2F</url>
    <content type="text"><![CDATA[VM 如果开机状态下，可以作为母本进行一次克隆任务。而关机状态下，则可以进行多次克隆任务。一般情况下，VM 进行多次克隆是没问题的，但如果目标数据存储的块大小不支持与源一样大的 VMDK，克隆或者迁移的时候则会出现由文件 [datastore1] VM1/VM1.vmdk 引起的错误，KB2101966 阐述了这个错误，但没有提供解决办法，甚至差点误导了我的方向，去研究 VMFS 数据存储的块大小限制 KB2074624。 本人的环境经常需要克隆 VM ，且数量不少。一个一个克隆是效率低下，无能的做法。要解决此问题，就要找出源头 故障现象：发起两个克隆任务，第一个克隆成功第二个秒失败。 故障分析：分析自身环境:多个VC下多个DC的清单中都注册了该 VM 作为克隆模版。 分析日志：先获取失败任务的ID，获取方法我的任务ID 是 task-192681看一下 VC 和相关的两台 ESXI 的常见的几个日志（VC的日志、VMware 产品的日志文件位置），以任务ID 为关键词筛选出内容，看看有没有记录一些有利于解决问题的信息，如下 vpxd-391.log:2016-12-28T03:16:08.465Z error vpxd[7F026F0D7700] [Originator@6876 sub=VmProv opID=c4000f-c6] Failed to track task vim.Task:==task-192681==on host vim.HostSystem:host-2663: vim.fault.FileFaultvpxd-391.log:2016-12-28T03:16:08.465Z error vpxd[7F026F0D7700] [Originator@6876 sub=VmProv opID=c4000f-c6] Aborting task tracking since task vim.Task:task-192681 failedvpxd-391.log:2016-12-28T03:16:08.465Z error vpxd[7F026F0D7700] [Originator@6876 sub=Datastore opID=c4000f-c6] [VpxdDatastore::UrlToDSPath] Received a non-url [/vmfs/volumes/57916ad0-f8a8e2f0-ce88-8cdcd4b658e4/W2K8R2-WEB-TEMP-V6/W2K8R2-WEB-TEMP-V6.vmdk], instead of a urlvpxd-391.log:2016-12-28T03:16:08.475Z error vpxd[7F026F0D7700] [Originator@6876 sub=VmProv opID=c4000f-c6] [WorkflowImpl] Get exception while executing action vpx.vmprov.CopyVmFiles: vim.fault.FileFault 时间点很吻合虽然找出了日志了，但只是说明报错了。解决办法还需要依靠厂商或者KB（中文关键词很难查的）、搜索引擎 后来找 VMware 开 CASE ，后台扔了个 KB 过来KB2119247按照 KB 的方法，解决了这个问题，操作摘抄如下： 删除与虚拟机模板关联的所有 -ctk.vmdk 文件。完成后，禁用更改块跟踪 (CBT)。 要删除与虚拟机模板关联的所有 -ctk.vmdk 文件，请执行以下操作： 通过 vSphere Client 或 vSphere Web Client 使用管理员凭据登录到 VMware vCenter Server。 浏览受影响虚拟机模板所在的 VMFS 数据存储。 从 VMFS 数据存储中移出或删除所有关联的 -ctk.vmdk 文件。 要禁用更改块跟踪 (CBT)，请执行以下操作： 关闭虚拟机电源。 右键单击虚拟机，然后单击编辑设置。 单击选项选项卡。 单击“高级”区域下方的常规，然后单击配置参数。此时将打开“配置参数”对话框。 请将相应 SCSI 磁盘的 ctkEnabled 参数设置为 false。 关于 CBT数据块修改跟踪技术(Changed Block Tracking)是vmware简化和提高虚拟机备份效率的重要组成部分，它可以实现只备份变化块数据，而不需要备份全部数据，减少备份数据，提高备份效率。]]></content>
      <categories>
        <category>VMware运维</category>
      </categories>
      <tags>
        <tag>CBT</tag>
        <tag>克隆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 vCSA 6.0 vphere-web-client-页面无法打开]]></title>
    <url>%2F2016%2F11%2F15%2Fvcsa-web-client-svc%2F</url>
    <content type="text"><![CDATA[故障描述5.5 版本 VMWare 就提倡用 web-client ，但是 web-client 的响应时间以及被动刷新真的很让人捉急，因此大部分人还是喜欢用 vsphere-client for desktop 。前端发现web-client无法打开，但是：5480 后台以及引导页面还是可以打开的。也就是https://#you-vc# /vsphere-client/?csp初步估计是 VC 的 web 服务异常了 排错解决SSH 上去 check 一下 vcsa:~ # /etc/init.d/vsphere-client status VMware vSphere Web Client is running: PID:14701, Wrapper:STARTED, Java:STARTED 正在运行，但页面就是打不开。重启服务试试 vcsa:~ # /etc/init.d/vsphere-client restart 等一分钟左右，刷新页面，登录界面出来了 除此之外，遇到别的异常可考虑重启对应的功能模块来尝试解决修复 vCSA 服务列表 服务名称 描述 applmgmt VMware Appliance Management Service vmware-cis-license VMware License Service vmware-cm VMware Component Manager vmware-eam VMware ESX Agent Manager vmware-sts-idmd VMware Identity Management Service vmware-invsvc VMware Inventory Service vmware-mbcs VMware Message Bus Configuration Service vmware-netdumper VMware vSphere ESXi Dump Collector vmware-perfcharts VMware Performance Charts vmware-rbd-watchdog VMware vSphere Auto Deploy Waiter vmware-rhttpproxy VMware HTTP Reverse Proxy vmware-sca VMware Service Control Agent vmware-sps VMware vSphere Profile-Driven Storage Service vmware-stsd VMware Security Token Service vmware-syslog VMware Common Logging Service vmware-syslog-health VMware Syslog Health Service vmware-vapi-endpoint VMware vAPI Endpoint vmware-vdcs VMware Content Library Service vmafdd VMware Authentication Framework vmcad VMware Certificate Service vmdird VMware Directory Service vmware-vpostgres VMware Postgres vmware-vpx-workflow VMware vCenter Workflow Manager vmware-vpxd VMware vCenter Server vmware-vsm VMware vService Manager vsphere-client vSphere Web Client vmware-vws VMware System and Hardware Health Manager vmware-vsan-health VMware vSAN Health Service 其它命令运行以下命令以列出 vCenter Server Appliance 服务： service-control –list 要查看 vCenter Server Appliance 服务的当前状态，请键入以下命令： service-control –status 运行以下命令以启动特定服务： service-control –startservicename 也可以键入以下命令启动所有服务： service-control –start –all 要执行该命令的预演，请将–dry-run选项添加到该命令。此时将显示该命令将运行哪些操作，而不执行这些操作。例如，键入以下命令： service-control –start –all –dry-run 运行以下命令以停止特定服务： service-control –stopservicename 也可以键入以下命令停止所有服务： service-control –stop –all 要执行该命令的预演，请将–dry-run选项添加到该命令。此时将显示该命令将运行哪些操作，而不执行这些操作。例如，键入以下命令： service-control –stop –all –dry-run 也可以键入以下命令停止所有服务： service-control –stop –all 运行以下命令以启动特定服务： service-control –startservicename 也可以键入以下命令启动所有服务： service-control –start –all 服务列表以及其它命令来自官方 KB2115730]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>排障</tag>
        <tag>虚拟化</tag>
        <tag>VCSA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[另类方式实现 VCS5.5 安全有效地"升级"至 vCSA6.0]]></title>
    <url>%2F2016%2F10%2F13%2Fvc5-upto-vcsa6%2F</url>
    <content type="text"><![CDATA[常规升级方式VCS (vCenter Server for Windows)平滑升级到 vCSA (vCenter Server Appliance) ？ 对不起，这种操作在6.0之前 官方文档是不存在的。VCS 是运行在 Windows 之上的虚拟化管理程序，而 vCSA 是运行在 Linux 上的，且是由 VMWare 定制开发好的appliance ，这也是 vCSA 的 A。两者的管理功能在6.0后几乎一样，但却是使用的底层操作系统，中间件，数据库都有极大的不同，无法平滑升级，数据无法从 VCS 导出，然后导入到 vCSA ，当中涉及到太多利害关系了，光网络和数据库就够你喝一壶（ps:vCSA比VCS 部署和架构都简单，而且能省掉M$的License）虽然之前在Flings 上有大神做了一个 VCS to VCVA Converter 的转换程序，之后正式被官方集成生产——vCenter Server Appliance (VCSA) Migration Tool officially GAs w/vSphere 6.0 Update 2m 我的方式 VCS to VCVA Converter 很早之前我就做了实验去验证，那时候实验环境比较简单，所以试了两次后，便完成验证了。在接触到复杂的虚拟化环境后，我开始考虑到这个物件的不确定性了，每个环境的管理者的技术水平都不是同一水平的，因此环境变得不可捉摸，如果有别的物件如监控，备份的依赖 VCS ，那转换成 VCSA 就很可能发生不可预测的错误，转换失败虽然不会破坏 VCS 的数据，但转换过程需要把 VCS 关机 ，但做我们这一行，很忌讳服务器关机/重启，因为很可能就启动不了或者启动失败。整好，目前我管理的虚拟化环境VCS 5.5 有升级到 VCSA 的需求，而且环境巨复杂，简单的说一下： 有4个集群，有的集群多达 30 个 ESXI-HOST 主机，几乎是vSphere 5.5 的最高配置。 每个集群独立的 VDS (虚拟分布式交换机)，总 VDP （分布式端口组）超过 200 个 每个 VDS 都关联了两个上联口 总 VM 数量超过 1000 个 每个 VM 的网卡都挂载了一个 VDP （分布式端口组），可怕吧····· 因此我在寻求一种平滑升级的方式，尽量的、原生的，可持续的完成VCSA 接管 VCS 的ESXI、VM、分布式虚拟网络配置等。后来在 PowerCLI 上看到了可能 思路利用跑业务流量的双网卡冗余特点，编写脚本实现精准切换端口组 先部署 VCSA6.0（已部署） 在 VCSA 上创建与 VC一样的集群架构，以及分布式交换机的端口组一致（脚本保证一致性） 通过脚本控制 VDS (分布式端口组)-&gt; VSS (标准端口组)的精准切换（保证端口组的影响降到最低） 把 ESXI 注册到 VCSA 上，VM 绑定在 VSS，注册过程不受影响 通过脚本回切端口组（VSS -&gt; VDS） 迁移图示 特点除了第一步，其余步骤均是通过脚本实现以 ESXI 为单位逐台注册到 VCSA，随时可中断回滚，为了解决 VDS 与 VM 之间的关联关系，VM 先绑定在 VSS 上，脱离了对 VDS的影响。一切变更操作设计以保护VM链路不中断为原则；整个变更中，基本上是管理上的调整，不会改变ESXI既定的物理网络配置 难点因为涉及到 VM 网卡上的端口组配置变换，必须保证绝对的精准记录每个 VM 网卡上面的 连接的端口组名称是什么，新建的 VDP 的 VLAN 号必须要跟原来的端口组 VLAN 号一致。我的解决办法是，导出这些配置，然后根据导出的内容，在新建的 VSS 上创建相应的端口组，且端口组名称尽量还是要增加标识来区分，来维护全局唯一的规则，这样降低报错和变更风险。 风险正在变更的ESXI上负载的VM在切换端口组的时候可能会有1~2个丢包的影响，类似情况就是双线冗余的业务链路断开了一线，正在使用该链路的流量会从另一个冗余的链路过来。 PowerCLI 脚本需要在PowerCLI把新旧两个VC都Login上1234$Cred = get-credentialConnect-VIServer "old-VC-address" -Credential $Cred -SaveCredentials -WarningAction SilentlyContinue$Cred1 = get-credentialConnect-VIServer "new-VC-address" -Credential $Cred1 -SaveCredentials -WarningAction SilentlyContinue 公共参数1234#把之前导出的HOST-VM-PG-VMNIC-LIST.csv 导入到变量中---------这部分导入适用于需要从表获取信息配置的操作$xpath = split-path -parent $MyInvocation.MyCommand.Definition$CsvPath= "$xpath\HOST-VM-PG-VMNIC-LIST.csv"$vmlists = Import-Csv $CsvPath -encoding Default | ?&#123;$_.deploy -like "*Y*" -and $_.VMHOST -eq $vmhost&#125; -ErrorAction SilentlyContinue 生成 HOST-VM-PG-VMNIC-LIST靠人是记不住，也记不完的，所以要把目前的配置导出（VM、VMHOST、VMNAME、NICNAME、NICMAC、PGNAME、VLAN、VSSPG、VSSNIC 、VDSNIC、VDSNAME）。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#导出指定 ESXI 主机的信息param($vmhost)$getvmhost = get-vmhost $vmhost -ErrorAction SilentlyContinue$getvds = $getvmhost | Get-VDSwitch$getcluster = $getvmhost | Get-cluster$getdc = $getvmhost | Get-Datacenter#获取 VDS 的端口组列表$getvdspg = $getvmhost | Get-VirtualPortGroup -Distributed#获取 VDS 的上联口$getvmnic = $getvds | Get-VMHostNetworkAdapter | ?&#123;$_.VMHOST -like $vmhost&#125;if($getvmnic.Count -eq 2)&#123;#获取 VDS 的两个上联口 $vdsnic = $getvmnic[0].name $vssnic = $getvmnic[1].name&#125;else&#123;#如果只有一个上联口，网络会中断的。 $vssnic = "none" $vdsnic = $getvmnic[0].name&#125;#获取每个 VM 的 NETINFOforeach($GETVM in $getvmhost | Get-vm)&#123;#遍历 ESXI 主机上的每个 VM foreach($GETVMNIC in $GETVM | Get-NetworkAdapter) &#123;#遍历 VM 上的每个 VNIC $VMname = $GETVM.name $nicname = $GETVMNIC.Name $nicmac = $GETVMNIC.MacAddress $pgname = $GETVMNIC.NetworkName $Newvsspg = "none" $PGVLAN = "none" if($getvdspg.name -contains $pgname) &#123;#判断 PG 是否是分布式端口组，如果是，则定义新建的对应的 VSS PG $Newvsspg = "VSS" +$GETVMNIC.NetworkName $PG = $getvdspg | ?&#123;$_.name -eq $pgname&#125; $PGVLAN = $PG.ExtensionData.Config.DefaultPortConfig.Vlan.VlanId &#125; #导出 $Y = "Y" $outlist = [PSCustomObject]@&#123; Deploy = $Y DC = $getdc.name Cluster = $getcluster.name VMHOST = $vmhost VMNAME = $VMname NICNAME = $nicname NICMAC = $nicmac PGNAME = $pgname VLAN = $PGVLAN VSSPG = $Newvsspg VSSNIC = $vssnic VDSNIC = $vdsnic VDSNAME = $getvds.name &#125; $outlist | Export-CSV -Path $CsvPath -Append -NoTypeInformation -encoding Default &#125;&#125; 在新的VC创建对应的VDS以及VDPG1234567891011121314151617181920212223242526#因为集群可配置项比较多，每人的要求都不尽想停，没写自动创建集群，需要在新的VC上手动创建Cluster。#新建VDSforeach($creatvds in $vmlists | Select-Object -Property DC,VDSNAME -Unique)&#123;##指定一下VDS的版本 $VER = "5.5.0" $DC = $creatvds.DC $VDS = $creatvds.VDSNAME $VDSinfo = Get-VDSwitch $VDS -ErrorAction SilentlyContinue if($VDSinfo -eq $null) &#123;#如果没有VDS则创建 $myDC = Get-Datacenter -Name $DC New-VDSwitch -Name $VDS -Location $myDC -NumUplinkPorts 2 -LinkDiscoveryProtocol "LLDP" -LinkDiscoveryProtocolOperation "Listen" -Version $VER -Confirm:$false -RunAsync | OUT-NULL write-host "$DC 创建 $VDS 成功。" -f green &#125; &#125;#获取现有的VDSPG清单$VDSPG = Get-VDPortgroup -VDSwitch "$VDSNAME" | Where &#123; $_.Name -NotMatch "-DVUplinks" &#125;#循环需要创建的VDPG清单foreach($creatvdspg in $vmlists | Select-Object -Property VDSNAME,VLAN,PGNAME -Unique)&#123; $VDS = $creatvdspg.VDSNAME $PG = $creatvdspg.PGNAME $VLAN = $creatvdspg.VLAN Get-VDSwitch -Name $VDS | New-VDPortgroup -Name $PG -NumPorts 8 -VLanId $VLAN -RunAsync | OUT-NULL write-host "$VDS 创建 $PG 成功。" &#125; 创建临时 VSW 标准虚拟交换机123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#操作指定的ESXI主机$getvmhost = get-vmhost $vmhost -ErrorAction SilentlyContinue#临时的虚拟交换机的名称，如果冲突请修改后面的数字$vssw = "vSwitch2" $getvmhost | New-VirtualSwitch -Name $vssw | out-null"$vssw 创建成功"Start-Sleep -Seconds 1#获取相关对象 （已经创建的vsw，目前vsw所关联的nic，目前vds所关联的nic，目前vsw上已经存在的vpg）$getvsw = $getvmhost | Get-VirtualSwitch -Name $vssw$getvssvmnic = $getvsw | Get-VMHostNetworkAdapter -Physical$getvmnic = $getvmhost | Get-VDSwitch | Get-VMHostNetworkAdapter | ?&#123;$_.VMHOST -like $vmhost&#125;$getvspg = $getvmhost | Get-VirtualPortGroup -Standard#根据之前导出的配置表，在新建的VSS上创建响应的端口组newvsspgforeach($creatvsspg in $vmlists | Select-Object -Property Deploy,VMHOST,VLAN,VSSPG -Unique)&#123; $vlanid = $creatvsspg.VLAN $vsspg = $creatvsspg.VSSPG if($vsspg -eq "none") &#123;&#125; elseif($getvspg.name -contains $vsspg) &#123; "$vsspg 已存在,跳过" &#125; else &#123; $getvsw | New-VirtualPortGroup -Name $vsspg -VLanId $vlanid -confirm:$false | Out-Null "$vsspg 创建成功" &#125;&#125;if($getvssvmnic.count -eq 0)&#123;#判断如果VSS没有挂载VMNIC,移除VDS的VSSNIC出来 foreach($migratevmnic in $vmlists | Select-Object -Property Deploy,VMHOST,VSSNIC,VDSNIC,VDSNAME -Unique) &#123;#迁移VDS-VMNIC到VSS-VMNIC $VSSNIC = $migratevmnic.VSSNIC $VDSNIC = $migratevmnic.VDSNIC if($VSSNIC -eq "none" -or $VDSNIC -eq "none") &#123;"0"&#125; elseif($getvmnic.name -contains $VSSNIC -and $getvmnic.name -contains $VDSNIC) &#123;#必须两个 VMNIC 都在 VDS-UPLINK 中才能移除 VSSNIC,并挂载到 VSSW $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VSSNIC | Remove-VDSwitchPhysicalNetworkAdapter -confirm:$false $getvssnic = $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VSSNIC $getvsw | Add-VirtualSwitchPhysicalNetworkAdapter -VMHostPhysicalNic $getvssnic -confirm:$false &#125; elseif($getvmnic.name -notcontains $VSSNIC -and $getvmnic.name -contains $VDSNIC) &#123;#如已经移除则挂载 VSSNIC 到 VSSW $getvssnic = $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VSSNIC $getvsw | Add-VirtualSwitchPhysicalNetworkAdapter -VMHostPhysicalNic $getvssnic -confirm:$false &#125; &#125;&#125;else&#123; read-host "$vssw 已存在 $getvssvmnic "&#125; 重定向VM的NIC端口组至VSS端口组1234567891011foreach($vmlist in $vmlists | Select-Object -Property PGNAME,VSSPG -Unique)&#123; $PGNAME = $vmlist.PGNAME $VSSPG = $vmlist.VSSPG if($VSSPG -ne "none") &#123;#把该ESXI上的VDSPG迁移到VSSPG上, PG by PG $getvmhost | Get-VM | Get-NetworkAdapter | ?&#123;$_.NetworkName -eq $PGNAME&#125; | Set-NetworkAdapter -NetworkName $VSSPG -Confirm:$false -RunAsync | out-null "$getvmhost $PGNAME ==&gt; $VSSPG DONE." #这一步会把操作的ESXI-HOST 上所有关联到VDSPG的VM-NIC，重定向关联到VSSPG上 &#125;&#125; 移除/新建分布式交换机12345678910111213141516$VDSinfo = $vmlists | Select-Object -Property VDSNIC,VDSNAME -Unique$VDSNIC = $vdsinfo.VDSNIC$VDSNAME = $vdsinfo.VDSNAME$getvdsw = Get-VDSwitch $VDSNAMEif($getvds -ne "none")&#123;#如果还没有移除则 $getvdsw | Remove-VDSwitchVMHost -VMHost $getvmhost -Confirm:$false read-host "已移除VDS,确认再从VC中移除$vmhost 则按回车继续" Set-VMHost -VMHost $getvmhost -State "Disconnected" | out-null&#125;else&#123;#如果没有注册到新的VDS.. $getvdsw | Add-VDSwitchVMHost -VMHost $getvmhost $GETVMHOSTNIC = $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VDSNIC $getvdsw | Add-VDSwitchPhysicalNetworkAdapter -VMHostNetworkAdapter $GETVMHOSTNIC -Confirm:$false&#125; 添加ESXI到指定的位置1234567891011if(!$getvmhost -eq $null)&#123;#使用ESXI的凭据 添加到新的VC指定的位置 $users="root" $password="password" $Datacenter = "Datacenter" $Cluster = "Cluster" read-host "按回车确认添加 $vmhost 到 $Datacenter 集群 $Cluster 吗?! 请等待添加完成后再执行任务4 " Add-VMHost -Name $vmhost -Location (Get-Datacenter $Datacenter | get-cluster $Cluster) -User $users -Password $password -force:$true -RunAsync -Confirm:$false | Out-Null Start-Sleep -Seconds 30 #完成后最好等个 30 秒。因为新的 ESXI 加入集群要初始化 HA 状态&#125; 重定向VM的NIC端口组至VDS端口组12345678910111213141516171819202122232425262728293031323334353637383940414243foreach($vmlist in $vmlists | Select-Object -Property PGNAME,VSSPG,VSSNIC,VDSNAME -Unique)&#123; $PGNAME = $vmlist.PGNAME $VSSPG = $vmlist.VSSPG $VSSNIC = $vmlist.VSSNIC $VDSNAME = $vmlist.VDSNAME #把该ESXI上的VSSPG迁移到VDSPG上,按PG来 if($VSSPG -ne "none") &#123; $getvmhost | Get-VM |Get-NetworkAdapter | ?&#123;$_.NetworkName -eq $VSSPG&#125; | Set-NetworkAdapter -NetworkName $PGNAME -Confirm:$false -RunAsync | out-null "$getvmhost $VSSPG ==&gt; $PGNAME DONE." &#125;&#125;Start-Sleep -Seconds 3#检查VSW上还有没有没被处理的VM$vssw = "vSwitch2" $getvdsw = Get-VDSwitch $VDSNAME$getvssw = Get-VirtualSwitch $getvmhost -Name $vssw$vspgnum = $getvssw | Get-VirtualPortGroup$vspgvmnum = $getvssw | Get-VM$vmnum = $vspgvmnum.count" $vssw 上共有 $vmnum 个VM ,如果存在VM,请检查"read-host "按回车确认移除VSS,并把$VSSNIC 添加至 VDS $VDSNAME"if($vspgvmnum.Count -eq 0)&#123;#只有VSSPG上没有挂载VM,才可以移除VSSPG,归还VMNIC给VDS Remove-VirtualSwitch -VirtualSwitch $getvssw -Confirm:$false $GETVMHOSTNIC = $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VSSNIC $getvdsw | Add-VDSwitchPhysicalNetworkAdapter -VMHostNetworkAdapter $GETVMHOSTNIC -Confirm:$false "移除VSS, $VSSNIC 添加至 VDS $VDSNAME DONE"&#125;else&#123; "$vssw 上连接了 $vmnum 个VM ,请检查并移除后继续" read-host $vspgvmnum = $getvssw | Get-VM if($vspgvmnum.Count -eq 0) &#123;#直到VSSPG上没有挂载VM Remove-VirtualSwitch -VirtualSwitch $getvssw -Confirm:$false $GETVMHOSTNIC = $getvmhost | Get-VMHostNetworkAdapter -Physical -Name $VSSNIC $getvdsw | Add-VDSwitchPhysicalNetworkAdapter -VMHostNetworkAdapter $GETVMHOSTNIC -Confirm:$false "移除VSS, $VSSNIC 添加至 VDS $VDSNAME DONE" &#125;&#125; 简单新建代替会死吗？当我提出这个方案的时候，很多人问我的一个问题。其实并不会死，指示会让你麻烦死。首先，肯定不能直接在集群里移除ESXI，你只能断开连接这个ESXI其次，未从 VDS 移除 ESXI ，ESXI 会残留这原来的VDS信息，直接去注册到别的 VDS ，你需要替换对应的端口组，但很不幸的告诉你，这个时候你已经无法看到VM的网卡原来关联的端口组名称是什么了，这会让你的运维带来困境。万一你选错关联的端口组。VM 的网络会中断。 运行好好的为什么升级？通过从 VC5.5 升级到使用 VCSA6.0 可获得以下收益。 支持更大的集群规模，支持 64 个主机组成集群 为后续ESXi5.5 升级到 ESXi6.0 夯实基础 节约额外的授权费用（VC需要Windows，sql server授权，VCSA则不需要） 节省独占物理主机的运营成本 部署 VCSA 比 VC 要更快 日常运行效率更高 可获得虚拟机的高可用，数据保护，中高端存储的性能优势 灵活的增配VC资源 两个VC共享验证凭据，SSO单点登陆]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>PowerCLI</tag>
        <tag>vCenter</tag>
        <tag>vCSA</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[研究IDC基础设施-服务器组件选型]]></title>
    <url>%2F2016%2F07%2F27%2Fidc-server-device-spec%2F</url>
    <content type="text"><![CDATA[服务器是 IDC 基础设施的重要组成元素之一，还有交换机、路由器等网络设备。选型服务器一般只要对标 CPU、内存、规格外形、硬盘的需求即可，这种套路对于小规模部署还是比较简单适用的。但在大规模的IDC基础设施环境中，动不动就上百台服务器的量级，非常讲究批次的组件一致性，一旦选错了，轻则增加运营成本，重则因为功能或者扩展性的问题无法满足变化多端的业务需求。那如何从需求和成本之间找到平衡？这需要决策者能否充分调研分析，既要满足现状也要具有前瞻的眼光去考量这个选型。简单的说下几个组件的选型思路 准系统框架 体积 1U : 1U 是一般中低端的服务器的标准身材，适合负载一些需要独占资源的单一应用。比如AD,NTP,Mgmt,跳板等用途。CPU一般可配备1~2个； 2U : 2U 很多中高端服务器的采用的体积规格，高度刚刚适合2.5寸硬盘竖插，很适合设计存储节点，另外目前很流行的高密度节点 2U2N(2U内2个计算节点)、2U4N(2U内4个计算节点)，高密度节点共享电源以及每节点分配本地存储空间，其它的都是独立的。适合偏计算，对本地存储无太大需求的用途，适合计较机柜空间、成本的管理者。CPU一般可配备1~4个； 4U ：4U 高端服务器，厚实的巨无霸，扩展性方面完全可覆盖90%需求，无论是CPU/内存/硬盘的扩展都可以达到一般的应用系统的上限，CPU一般可配备1~8个，特点是贵，无论是CAPEX还是OPEX！ CPU 插槽 双路 现在服务器设计最低都是双路起，可以插一个CPU，另一个不插，但是根据目前流行 NUMA 架构，你可能会损失一半的内存插槽是无法被CPU识别的。 内存 插槽 应不少于24插槽 PCI 插槽 不少于4 插槽 ，具体按实际需求来，万兆网卡 /PCI 阵列卡 /PCI 闪存卡/ 显卡 硬盘插槽 一般不少于 24 个，最好建议一步到位，同时要注意选购的阵列卡是否支持这么多硬盘。 主板其它功能 基于IPMI标准的带外管理，双电源+冗余，支持legacy BIOS、uEFI两种模式的固件 计算 处理器 处理器版本（工艺制程） 内核数量，虚拟化用途建议不少于12 LLC 三级缓存，虚拟化用途建议不低于30MB 内存 DDR4 频率 时延 单条容量 存储 阵列卡 缓存 支持组RAID方式 RAID 0/1/2/5/6/10 磁盘 尺寸 2.5、3.5 转速 5.4k/7.2k/10k/15k 容量 接口 SAS、NL-SAS 固态硬盘 颗粒 TLC/MLC/eMLC/SLC/Optane OP 即预留空间 建议不低于20% DWPD 不低于10 容量 接口 SAS、PCI-e 协议 SCSI、NVMe 其它组件 主板 具备耐高温长期稳定运行特点，主板耐腐蚀涂层 电源 不少于2*电源模块，转换效率不低于90% 带外管理 标准IPMI带外管理 管理 维护 免工具维护，模块化设计]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集中式存储 VS 分布式存储]]></title>
    <url>%2F2016%2F06%2F05%2Fstorage-share-vs-distribute%2F</url>
    <content type="text"><![CDATA[类型 特点 优点 缺点 集中式存储 存储设备集中在一起管理，由单一存储甚至是几个大型存储设备，分配存储资源给众多服务器使用，资源隔离细粒度有限。 1. 产品丰富，买来即用。 2. 单一性能可以堆到很高，一荣俱荣。 3. 市场成熟，商业化产品互操性、兼容性佳。 1. 数据处理集中，全局影响，不适合多租户； 2. 烟囱式扩展. 硬件捆绑. 成本昂贵； 3. 架构复杂，故障排查难度大； 4. 资源捆绑. 一损俱损； 5. 建设周期长，无法快速供给； 分布式存储 软件定义存储，利用X86服务器本地磁盘与高速网络结合，形成一个大的存储资源池，基于这个资源池可以衍生多种存储类型，如对象存储，随着节点规模越大，性能线性水平增长，特别适合大规模数据中心，多租户场景 1. 架构简单、扩展性极强，易于管理，自动化程度高。 2. 数据分散在不同服务器上形成冗余级数据保护。 3. 采用本地IO路径，路径更短，延迟更低。 4. 标准X86服务器和磁盘组成，低成本，采购周期短。 1. 需要高速低延迟网络环境 2. 需要多个以上节点组成 3. 要有一定的运维能力和自动化程度的环境]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>集中式存储</tag>
        <tag>分布式存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主流计算虚拟化技术对比]]></title>
    <url>%2F2016%2F04%2F02%2Fvirtualization-tech-comparison%2F</url>
    <content type="text"><![CDATA[VMWare产品形态：商用产品代表：vSphere ESXi、Workstation特点：产品成熟稳定，企业级市场份额最大；对计算（CPU/内存）的管理调度有特别好的优化优势： 功能，产品线丰富，是行业的标杆 稳定成熟，通用，虚拟效率高 支持虚拟多种X86类型系统 劣势： 大规模部署下成本昂贵 自动化、二次开发成本高，需要研发人力 应用范围： 私有云：70%中小型企业首选 公有云：天翼公有云 Hyper-V产品形态：商用产品代表：Windows Server 2008/2012/2016特点：微内核架构优势： 设备驱动跟内核松耦合 微内核架构，代码少，初始化快 对WINDOWS支持更佳 劣势： 成本昂贵，需要企业版许可 没有API接口，修复补丁多 架构复杂，对资源和管理、故障迁移有待提高 对LINUX支持不是很好 应用范围： 小部分中小型企业基于成本考虑使用 微软 AZURE （未确定） KVM产品形态：开源产品代表：OpenStack特点：定制性强，免费优势： 社区庞大，资源丰富 免费，使用成本低 有大规模部署的实践验证 集成到LINUX内核中 劣势： 深度调优，虚拟化效率才高 单独使用功能有限，需要配置多个组件实现功能，开发能力要求高多 应用范围： 私有云：技术开发实力强的互联网公司，小米，唯品会 公有云：腾讯云，阿里云（新的数据中心已经采用 KVM 技术），青云，Ucloud等 XEN产品形态：开源产品代表：CloudStack特点：定制性强，免费优势： 社区庞大，资源丰富 免费，使用成本低 有大规模部署的实践验证 劣势： 深度调优，虚拟化效率才高 单独使用功能有限，需要配置多个组件实现功能，开发能力要求高多 应用范围： 私有云：华为（基于思杰的 XEN 技术，目前已经开发 KVM 版本） 公有云：AWS，阿里云（准备转 KVM 架构）]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机释放磁盘空间]]></title>
    <url>%2F2015%2F12%2F07%2Fvm-space-reclaim-disk-vmdk%2F</url>
    <content type="text"><![CDATA[事实上虚拟机 Geust OS 存放了数据占用空间后再删除到回收站清理，对于VMware Datastore 的 VMFS文件系统来说无法直接感知到的，所以会常常有管理员觉得，虚拟机明明删掉了 100G 的数据，为啥在 VC 上面看到这个虚拟机占用的空间还是没有减少。 想要 Geust OS 把清理后的空间还给 Datastore ，换句话意思 Datastore 想识别到 Geust OS 释放出来的空间，则需要 Geust OS 重新把闲余空间进行一个置零操作，然后要使用 vmfstool 对相关的 VMDK 进行置零操作。整个过程数据不会丢失。 Windows使用 Sdelete.exe 此命令行工，可以跟踪非零的垃圾块和未使用的块并将它们释放回数据存储中，有效地缩小磁盘。1sdelete -c -z C:\ 执行过程，磁盘空间会一点点的被消耗，但不要担心。等待完成。 Linux1$ dd if=/dev/zero of=/[mounted-volume]/zeroes &amp;&amp; rm -f /[mounted-volume]/zeroes 在 ESXI 上回收空间关闭VM的 Geust OS 系统，SSH 到任意能访问这个 VM 所在的 Datastore ESXI 主机开始回收 VMDK 空间 1vmkfstools -K /path/disk-name.vmdk]]></content>
      <categories>
        <category>VMware运维</category>
      </categories>
      <tags>
        <tag>command</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Powershell 远程管理服务器]]></title>
    <url>%2F2015%2F11%2F18%2Fpowershell-mag-remote-host%2F</url>
    <content type="text"><![CDATA[管理环境-条件 远程服务器（客户端） 默认情况下，PowerShell 禁止 PowerShell 脚本在 Windows 系统中执行。需要修改策略来解除。 PowerShell 管理员模式下执行： 1Set-ExecutionPolicy bypass 启用远程处理模式 1Enable-PSRemoting -force 管理服务器（管理端） 添加信任列表，PowerShell 管理员模式下执行： 1Set-Item WSMan:\localhost\Client\TrustedHosts -Value * -force 扩展远程操作主要依赖几个Session（会话）命令和Invoke-Command命令来进行。总结下 Enter-PSSession 远程交互式会话 这个场景一般用于手动进行远程操作，输入命令，查看结果。方法很简单。进入交互式会话的命令是Enter-PSSession，退出时键入Exit-PSSession或者exit都可以。远程交互式操作期间，输入的命令在远程计算机上运行，就像直接在远程计算机上输入并执行这些命令一样。期间所定义的变量和命令的执行结果在退出交互式会话之后不再可用。 New-pssession 建立会话执行一次性操作 这种在本地计算机与远程计算机上建立一个临时会话。将脚本块或者脚本文件的内容发送到远程计算机执行，并将结果发回本地计算机。这种方法执行效率很高，是PowerShell推荐的执行远程命令的方法。除非需要在会话中共享数据，否则建议使用该使用方法。注意，会话数量是有限制的，用完务必释放会话。 Invoke-Command 命令/脚本在命名会话中执行 用 New-pssession 建立会话并保存到一个变量中，然后在Invoke-Command中指定会话使用该变量。可将执行结果赋予到新的变量中 格式： 1$sub = Invoke-Command -Session $session1 -ScriptBlock &#123;dir c:\&#125; 其它PowerShell 在网络处理方面有诸多限制。比如 PowerShell 不能在远程机器上显示界面，即使是有界面的程序，也只能在后台运行。]]></content>
      <categories>
        <category>Powershell</category>
      </categories>
      <tags>
        <tag>Powershell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[故障排错-ESXI-VM无法启动以及迁移且SSH/shell服务无法启动]]></title>
    <url>%2F2015%2F11%2F11%2Fesxi-Troubleshooting-svc-donowork%2F</url>
    <content type="text"><![CDATA[故障信息对象：ESXI 主机现象：虚拟机无法正常开机，正在运行的虚拟机无法迁移到别的主机，SSH/shell服务挂死、重启启动失败。尽量不能直接重启ESXI主机，会中断正在运行的虚拟机 排错步骤1、先把SSH/shell服务重新变为可用1控制台重启 manager server 2、但第二个问题诞生了，正在 此ESXI 主机上运行的虚拟机在 VC 上变成无效了 ，状态为未知12345SSH上去，使用 esxtop 查看虚拟机是正在运行的出现这种情况是因为重启管理服务之后HOSTD、VXPD服务起来之后无法读取到正在运行的虚机的VMX文件，无法读取配置文件。需要命令行迁移VM（测试过不行）或者重新启动VM。让VMX变为可读状态，hostd服务才能正确读取到虚机配置。 3、翻 KB2083312 找到了一个答案，解释了TRP文件过多，影响了ESXI主机的部分服务SSH上去一查，果然 4、通过运行以下命令删除 /var/spool/snmp/ 目录中的 .trp 文件：12# cd /var/spool/snmp# for i in $(ls | grep trp); do rm -f $i;done 要确保此问题不会重复发生，可暂时禁用 snmpd 以停止日志记录。要停止 snmpd 服务，请运行以下命令：1# /etc/init.d/snmpd stop 官方建议停止SNMPD这个服务，但是TRP文件依然增长，启用后，TRP文件却停止增长了。12snmpd is running# /etc/init.d/snmpd start 5、因为 trp 文件过多，所以对 ESXI 主机的服务状态进行维护变更会失败，现在清理完了，重新的把主要的服务 hostd 启动12/etc/init.d/hostd status /etc/init.d/hostd start Restart重启服务 start 启动服务 重启了 hostd 服务后，esxi主机的管理agent会短暂重启一下，并不会影响虚机，使用client重新连接ESXI主机后，hostd 能正确读取到正在运行的虚机状态。 另外如果资源池与虚拟机的目录关系有异常，把 vxpa 的服务也重新启动一下吧1/etc/init.d/vpxa restart]]></content>
      <categories>
        <category>VMWare运维</category>
      </categories>
      <tags>
        <tag>排障</tag>
        <tag>ESXI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析虚拟机文件会被 HA 锁-案列]]></title>
    <url>%2F2015%2F11%2F06%2FVM-FILE-LOCK-TS01%2F</url>
    <content type="text"><![CDATA[之前发生过集群中的有个ESXi与某个 Datastore ，导致虚拟机卡死宕机了，然后无法强制关机，通过命令杀死虚拟机后。提示找不到虚拟机文件，无法启动，去 Datastore 对应的虚拟机目录看，虚拟机 vmx 配置文件是无图标的，即锁定状态。无法 ESXI 被读取到。因此需要解锁，解锁要找到谁上锁，排障的过程搜索过资料和与官方工程师讨论后决定从虚拟机清单中移除虚拟机，手动删除去 Datastore 对应的虚拟机目录 .LCK 锁定文件，修改 VMXF 后缀后，VMX 文件恢复为可注册状态。但是依然无法开机，因为被锁的还有 VMDK 文件 ，奔溃的是 VMDK 的解锁方式还真有点不一样。刚好搜索资料的时候，找到一篇博文，分析是 HA 的原因 导致被锁的，如下： 故障现象：启动虚拟机时 95 %，停顿并且启动任务中断，提示：ubable to access files since it is locked。 原因分析：是HA的原因。 解决方法： 1、首先将cluster中的HA功能关闭。如果该功能不关闭，容易造成死锁,，VM不断跳动，不断再不同的ESX内循环被锁，徒劳而无功。 2、磁盘文件被锁，要解决，必须要知道到底是哪台ESX把他给锁住了，这是关键。 操作：看/var/log/vmkernel但是，在做这些前, 再准备些别的工作。 3、在VC中，把被锁的VM从Inventory中remove掉。原因很简单，这是一个 unregister的过程。 4、根据/var/log/vmkernel，搜索owner，可以找到类似以下的语句: 1Oct 19 04:23:33 esx-hostname vmkernel: 3:06:29:47.992 cpu6:1656)FS3: 1975: Checking if lock holders are live for lock [type 10c00001 offset 52008960 v 380, hb offset 3554304 Oct 19 04:23:33 esx-hostname vmkernel: gen 17, mode 1, owner 48f5f637-462688bc-fd28-0e1a6434b6f8mtime 38112] OK，owner后面的48f5f637-462688bc-fd28-0e1a6434b6f8就是你的target了。 因为他就是锁住VM 的宿主.。 5、根据以下命令,，找出到底哪台ESX的UUID是 48f5f637-462688bc-fd28-0e1a6434b6f8 1[iyunv@esxhostname root]# esxcfg-info |grep -i system uuid 6、找到目标主机后，当然是杀死他锁住VM的进程。之所以会被锁，原因就是HA 把VM从别的HOST迁移过来，但是又没有unregister和register的过程，所以在第3步的时候，你查看VM的Summary的时候，host ip还是属于出问题的 host。 但是VM又被新的host霸王硬上功的power on，注册都没注册, 又怎么启动呢。找到 PID 用下面的命令： 1ps -efwww|grep virtualmachine.vmx 找到 PID 后, kill -9 PID 7、此时需确定一件事情（.vswp文件）。这个是给台客处理问题时吸取的经验。就因为忽略了这个，所以在杀掉?程后，重新注册VM，还说没有 SWAP文件，启动还是失败。 在 VM 启动时会自动生成SWAP，没有SWAP文件，其实就是因为 SWAP 存在了, 因为重名而导致无法正常生成。 进入到/vmfs/volumes/lunid/vm_path/下，vmkfs -d virtual_machine.vswp 或者进入Datastore Browser，在里面把SWAP文件删除也可。 8、完全之策，你还可以进入到VM的SETTINGS–OPTIONS–SWAPFILE LOCATION， 对该保存的位置做下设置。 9、重新注册VM。进入Datastore Browser，找到VM.vmx，add to inventory。 10、启动VM。]]></content>
      <categories>
        <category>VMware运维</category>
      </categories>
      <tags>
        <tag>排障</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vSphere运维的一些命令]]></title>
    <url>%2F2015%2F07%2F05%2Fesxi-cmd-ops%2F</url>
    <content type="text"><![CDATA[命令行取消正在运行的任务1、SSH ESXi2、执行一下命令查询当前任务列表1#vim-cmd vimsvc/task_list 3、查看任务具体细节 “xxxxx” 代表任务ID1#vim-cmd vimsvc/task_info xxxxx 4、确认之后，执行以下命令取消任务1#vim-cmd vimsvc/task_cancel xxxxx 命令行杀死虚拟机1、SSH ESXi2、输入 esxtop , 打开 esxtop 界面3、输入C 切换到 CPU 资源界面 按shift + V 只显示 VMs 相关的信息 4、接着输入 F ，按 C 把 LWID 显示出来 5、按 K ，把需要杀死的虚拟机的LWID 输入回车即可 备份 ESXi 设定参数1、WinSCP 登录到 ESXi ，找到 /bootbank/state.tgz 拷贝出来2、然后进行要更改的设定3、如需要恢复更改之前的状态，直接把副本覆盖到目录下替换4、命令行执行 reboot -f 重启 vmkping默认情况下，ESXI 使用 PING 测试网络默认是用管理IP去发起的，如果是测试其它vmkernel的网络 则使用vmkping 禁用vSAN Health Service如果没有使用 vSAN , VC 的任务栏会被1启用了 Non-Virtual SAN 的 ESXi 主机显示以下消息：检索用来注册 Virtual SAN VASA 提供程序的票证 (Retrieve a ticket to register the Virtual SAN VASA Provider) 这个任务刷屏，及其讨厌不久前 KB2145594终于解决了这个问题了摘抄一下 vCSA 的操作 1、停止 vSAN Health Service：1# service vmware-vsan-health stop 2、禁用 vSAN Health Service：1# chkconfig vmware-vsan-health off]]></content>
      <categories>
        <category>VMware运维</category>
      </categories>
      <tags>
        <tag>ESXi</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化是什么]]></title>
    <url>%2F2014%2F08%2F08%2Fvirtualization-evo%2F</url>
    <content type="text"><![CDATA[引用WIKI 在计算机技术中，虚拟化（技术）或虚拟技术（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等），予以抽象、转换后呈现出来并可供分区、组合为一个或多个电脑配置环境。由此，打破实体结构间的不可切割的障碍，使用户可以比原本的配置更好的方式来应用这些电脑硬件资源。这些资源的新虚拟部分是不受现有资源的架设方式，地域或物理配置所限制。一般所指的虚拟化资源包括计算能力和数据存储。 虚拟化不是一个新技术，在上个世纪60年代就已经诞生了，真正在X86架构下广泛应用应该是在本世纪初由VMWare公司推出企业级vSphere 虚拟化软件产品，配合Intel 等厂商随着工艺的不断进步升级，物理服务器可以运行多个虚拟机，每个虚拟机可以负载不同的程序，极大的提高了物理服务器的资源利用率，同时也保持了程序之间隔离性。 虚拟化技术解决了什么问题虚拟化技术在那些领域中得到广泛应用选择虚拟化的思考点极大的提高资源的利用率缩减了企业的IT成本创新、先进是企业在竞争中重要的决胜关键点]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于这里]]></title>
    <url>%2F2014%2F07%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[记录我在IT技术的道路上探索实践中的点点滴滴目前专注方向-2017VMWare：vSphere/Horizon 安装、部署、规划、设计、管理、自动化运维 开发：Powershell、PowerCLI、Pyhton IDC基础设施：数据中心、机房机柜、服务器设备 数据管理：数据存储/管理/备份/复制/重删/压缩 扩展：基于VMWare环境的网络/存储/备份/灾备 云计算工程技术：虚拟化技术、SDS、SDN、CMP、IAAS、PAAS]]></content>
      <categories>
        <category>随手杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
</search>
